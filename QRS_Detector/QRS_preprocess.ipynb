{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QRS training data Preprocessor\n",
    "\n",
    "Data preprocessor to build the training and validation data for our neural network\n",
    "\n",
    "This notebook implementes all the necessary steps to run the computations needed to create the training and test data files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wfdb\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the parabola function\n",
    "\n",
    "This function will create a parabola around a spike in order to give it more width so it can be more easily detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auxiliary function\n",
    "def parabola(a,n,r):\n",
    "    \"\"\"\n",
    "    Creates a parabola around the position of a spike specified in 'a'\n",
    "    Params:\n",
    "        a - A vector specifying peak positions\n",
    "        n - The length of the target vector to generate\n",
    "        r - The radius of the parabola\n",
    "    \"\"\"\n",
    "    assert n>2*r\n",
    "    y = np.zeros(n, dtype = np.float32)\n",
    "    x= np.array(range(2,2*r+1))\n",
    "    for i in a:\n",
    "        if i > r-1 and i <= n-r:\n",
    "            y[i-r+1:i+r] = ((r+1)**2-(x-r-1)**2)/(r+1)**2\n",
    "        elif i < r:\n",
    "            y[:i+r] = ((r+1)**2-(x[r-i-1:]-r-1)**2)/(r+1)**2\n",
    "        elif i<n:\n",
    "            y[i-r+1:] = ((r+1)**2-(x[:r-1+(n-i)]-r-1)**2)/(r+1)**2\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the files\n",
    "\n",
    "We iterate all the files and for each of them we read channels II and V1.\n",
    "\n",
    "After reading the channels we separate them into two distinct arrays in order to then join them into one 1D array.\n",
    "\n",
    "We filter out undesired lines, i.e., lines that do not have a QRS symbol specified in `qrs_symbs` list.\n",
    "\n",
    "The negative positions in the `qrs_symbs` list are also filtered out.\n",
    "\n",
    "Once the lines are filtered we create a parabola around the spikes of our labels to better identify them, this completes the preprocessing of the data and we are now ready to create an output dictionary to be serialized into a file with `pickle`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing of the training datafiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/Training/I01\n",
      "./data/Training/I02\n",
      "./data/Training/I03\n",
      "./data/Training/I04\n",
      "./data/Training/I05\n",
      "./data/Training/I06\n",
      "./data/Training/I07\n",
      "./data/Training/I08\n",
      "./data/Training/I09\n",
      "./data/Training/I10\n",
      "./data/Training/I11\n",
      "./data/Training/I12\n",
      "./data/Training/I13\n",
      "./data/Training/I14\n",
      "./data/Training/I15\n",
      "./data/Training/I16\n",
      "./data/Training/I17\n",
      "./data/Training/I18\n",
      "./data/Training/I19\n",
      "./data/Training/I20\n",
      "./data/Training/I21\n",
      "./data/Training/I22\n",
      "./data/Training/I23\n",
      "./data/Training/I24\n",
      "./data/Training/I25\n",
      "./data/Training/I26\n",
      "./data/Training/I27\n",
      "./data/Training/I28\n",
      "./data/Training/I29\n",
      "./data/Training/I30\n",
      "./data/Training/I31\n",
      "./data/Training/I32\n",
      "./data/Training/I33\n",
      "./data/Training/I34\n",
      "./data/Training/I35\n",
      "./data/Training/I36\n",
      "./data/Training/I37\n",
      "./data/Training/I38\n",
      "./data/Training/I39\n",
      "./data/Training/I40\n",
      "./data/Training/I41\n",
      "./data/Training/I42\n",
      "./data/Training/I43\n",
      "./data/Training/I44\n",
      "./data/Training/I45\n",
      "./data/Training/I46\n",
      "./data/Training/I47\n",
      "./data/Training/I48\n",
      "./data/Training/I49\n",
      "./data/Training/I50\n",
      "./data/Training/I51\n",
      "./data/Training/I52\n",
      "./data/Training/I53\n",
      "./data/Training/I54\n",
      "./data/Training/I55\n",
      "./data/Training/I56\n",
      "./data/Training/I57\n",
      "./data/Training/I58\n",
      "./data/Training/I59\n",
      "./data/Training/I60\n",
      "./data/Training/I61\n",
      "./data/Training/I62\n",
      "./data/Training/I63\n",
      "./data/Training/I64\n",
      "./data/Training/I65\n",
      "./data/Training/I66\n",
      "./data/Training/I67\n",
      "./data/Training/I68\n",
      "./data/Training/I69\n",
      "./data/Training/I70\n",
      "./data/Training/I71\n",
      "./data/Training/I72\n",
      "./data/Training/I73\n",
      "./data/Training/I74\n",
      "./data/Training/I75\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 76):\n",
    "    \n",
    "    file_path = f\"./data/Training/I{i:02}\"\n",
    "    print(file_path)\n",
    "    output_file_name = f\"./processed_data/Training/I{i:02}\"\n",
    "    try:\n",
    "        # Reading the channels of interest\n",
    "        signal, info = wfdb.rdsamp(file_path, channel_names = [\"II\", \"V1\"])\n",
    "\n",
    "        # Separating the two signals so we can put them in one dimension\n",
    "        signal_II = signal[:, 0]\n",
    "        signal_V1 = signal[:, 1]\n",
    "\n",
    "\n",
    "        # Reading the annotations\n",
    "        annotations = wfdb.rdann(file_path, \"atr\")\n",
    "        symbol_positions = annotations.sample\n",
    "        symbol_list = annotations.symbol\n",
    "\n",
    "        # Filtering out all the lines that do not have a QRS symbol\n",
    "\n",
    "        qrs_symbs = ['N','L','R','B','A','a','J','S','V','r','F','e','j', 'n', 'E', '/', 'f', 'Q',' ?']\n",
    "\n",
    "        qrs_symbol_positions = [symbol_positions[idx] for idx, symb in enumerate(symbol_list) if symb in qrs_symbs]\n",
    "\n",
    "        # Some peak positions are negative values, we are filtering these negative values out\n",
    "        qrs_symbol_positions = [item for item in qrs_symbol_positions if item >= 0]\n",
    "        \n",
    "        target_vec = parabola(qrs_symbol_positions, len(signal), 3)\n",
    "\n",
    "        output_dict = {\n",
    "            \"features\": signal_II + signal_V1,\n",
    "            \"label\": target_vec\n",
    "        }\n",
    "\n",
    "        pkl.dump(output_dict, open(output_file_name, \"wb\"), protocol=pkl.HIGHEST_PROTOCOL)\n",
    "    except:\n",
    "        print(f\"Error on file {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example on how to read a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.94444444, -1.97385621, -1.95751634, ...,  4.44117647,\n",
       "        4.41176471,  4.45751634])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict = pkl.load(open(\"./processed_data/Training/I01\", \"rb\"))\n",
    "data_dict[\"features\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing of the test datafiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/Test/110\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-5cd3bd5b7017>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;31m# Reading the channels of interest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0msignal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwfdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdsamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;31m# Separating the two signals so we can put them in one dimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/wfdb/io/record.py\u001b[0m in \u001b[0;36mrdsamp\u001b[0;34m(record_name, sampfrom, sampto, channels, pb_dir, channel_names, warn_empty)\u001b[0m\n\u001b[1;32m   1393\u001b[0m                       \u001b[0mpb_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpb_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm2s\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannel_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchannel_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1394\u001b[0;31m                       warn_empty=warn_empty)\n\u001b[0m\u001b[1;32m   1395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/wfdb/io/record.py\u001b[0m in \u001b[0;36mrdrecord\u001b[0;34m(record_name, sampfrom, sampto, channels, physical, pb_dir, m2s, smooth_frames, ignore_skew, return_res, force_channels, channel_names, warn_empty)\u001b[0m\n\u001b[1;32m   1153\u001b[0m     \u001b[0;31m# Read the header fields\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m     \u001b[0mrecord\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrdheader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpb_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpb_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrd_segments\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/wfdb/io/record.py\u001b[0m in \u001b[0;36mrdheader\u001b[0;34m(record_name, pb_dir, rd_segments)\u001b[0m\n\u001b[1;32m    993\u001b[0m     \u001b[0;31m# Get fields from record line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m     \u001b[0mrecord_fields\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_header\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_record_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader_lines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/wfdb/io/_header.py\u001b[0m in \u001b[0;36m_parse_record_line\u001b[0;34m(record_line)\u001b[0m\n\u001b[1;32m    745\u001b[0m      \u001b[0mrecord_fields\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sig_len'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord_fields\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'base_time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 746\u001b[0;31m      record_fields['base_date']) = re.findall(_rx_record, record_line)[0]\n\u001b[0m\u001b[1;32m    747\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-5cd3bd5b7017>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m#traceback.print_exc()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0msignal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwfdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdsamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Error on file {file_path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/wfdb/io/record.py\u001b[0m in \u001b[0;36mrdsamp\u001b[0;34m(record_name, sampfrom, sampto, channels, pb_dir, channel_names, warn_empty)\u001b[0m\n\u001b[1;32m   1392\u001b[0m                       \u001b[0msampto\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msampto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphysical\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1393\u001b[0m                       \u001b[0mpb_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpb_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm2s\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannel_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchannel_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1394\u001b[0;31m                       warn_empty=warn_empty)\n\u001b[0m\u001b[1;32m   1395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1396\u001b[0m     \u001b[0msignals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp_signal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/wfdb/io/record.py\u001b[0m in \u001b[0;36mrdrecord\u001b[0;34m(record_name, sampfrom, sampto, channels, physical, pb_dir, m2s, smooth_frames, ignore_skew, return_res, force_channels, channel_names, warn_empty)\u001b[0m\n\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m     \u001b[0;31m# Read the header fields\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m     \u001b[0mrecord\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrdheader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpb_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpb_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrd_segments\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m     \u001b[0;31m# Set defaults for sampto and channels input variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/wfdb/io/record.py\u001b[0m in \u001b[0;36mrdheader\u001b[0;34m(record_name, pb_dir, rd_segments)\u001b[0m\n\u001b[1;32m    992\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m     \u001b[0;31m# Get fields from record line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m     \u001b[0mrecord_fields\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_header\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_record_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader_lines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m     \u001b[0;31m# Single segment header - Process signal specification lines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/wfdb/io/_header.py\u001b[0m in \u001b[0;36m_parse_record_line\u001b[0;34m(record_line)\u001b[0m\n\u001b[1;32m    744\u001b[0m      \u001b[0mrecord_fields\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'counter_freq'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord_fields\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'base_counter'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m      \u001b[0mrecord_fields\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sig_len'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord_fields\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'base_time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 746\u001b[0;31m      record_fields['base_date']) = re.findall(_rx_record, record_line)[0]\n\u001b[0m\u001b[1;32m    747\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfield\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mRECORD_SPECS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "nofile_indexes = [110, 120, 204, 206, 211, 216, 218, 229]\n",
    "nofile_indexes = nofile_indexes + list(range(125,200)) + list(range(224,228))\n",
    "\n",
    "for i in range(100, 235):\n",
    "    \n",
    "    if i not in nofile_indexes:\n",
    "        file_path = f\"./data/Test/{i}\"\n",
    "        output_file_name = f\"./processed_data/Test/{i}\"\n",
    "        try:\n",
    "            # Reading the channels of interest\n",
    "            signal, info = wfdb.rdsamp(file_path)\n",
    "            # Separating the two signals so we can put them in one dimension\n",
    "            signal_II = signal[:, 0]\n",
    "            signal_V1 = signal[:, 1]\n",
    "\n",
    "\n",
    "            # Reading the annotations\n",
    "            annotations = wfdb.rdann(file_path, \"atr\")\n",
    "            symbol_positions = annotations.sample\n",
    "            symbol_list = annotations.symbol\n",
    "            \n",
    "            # Filtering out all the lines that do not have a QRS symbol\n",
    "\n",
    "            qrs_symbs = ['N','L','R','B','A','a','J','S','V','r','F','e','j', 'n', 'E', '/', 'f', 'Q',' ?']\n",
    "\n",
    "            qrs_symbol_positions = [symbol_positions[idx] for idx, symb in enumerate(symbol_list) if symb in qrs_symbs]\n",
    "\n",
    "            # Some peak positions are negative values, we are filtering these negative values out\n",
    "            qrs_symbol_positions = [item for item in qrs_symbol_positions if item >= 0]\n",
    "\n",
    "            target_vec = parabola(qrs_symbol_positions, len(signal), 3)\n",
    "\n",
    "            output_dict = {\n",
    "                \"features\": signal_II + signal_V1,\n",
    "                \"label\": target_vec\n",
    "            }\n",
    "\n",
    "            pkl.dump(output_dict, open(output_file_name, \"wb\"), protocol=pkl.HIGHEST_PROTOCOL)\n",
    "        except:\n",
    "            #traceback.print_exc()\n",
    "            print(f\"Error on file {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.345, -0.16 ],\n",
       "        [-0.345, -0.16 ],\n",
       "        [-0.345, -0.16 ],\n",
       "        ...,\n",
       "        [-0.295, -0.11 ],\n",
       "        [-0.29 , -0.11 ],\n",
       "        [ 0.   ,  0.   ]]),\n",
       " {'fs': 360,\n",
       "  'sig_len': 650000,\n",
       "  'n_sig': 2,\n",
       "  'base_date': None,\n",
       "  'base_time': None,\n",
       "  'units': ['mV', 'mV'],\n",
       "  'sig_name': ['MLII', 'V1'],\n",
       "  'comments': ['75 F 1011 654 x1', 'Diapres']})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wfdb.rdsamp(\"./data/Test/101\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-10a1b48728f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwfdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdrecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./data/Test/110\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/wfdb/io/record.py\u001b[0m in \u001b[0;36mrdrecord\u001b[0;34m(record_name, sampfrom, sampto, channels, physical, pb_dir, m2s, smooth_frames, ignore_skew, return_res, force_channels, channel_names, warn_empty)\u001b[0m\n\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m     \u001b[0;31m# Read the header fields\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m     \u001b[0mrecord\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrdheader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpb_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpb_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrd_segments\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m     \u001b[0;31m# Set defaults for sampto and channels input variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/wfdb/io/record.py\u001b[0m in \u001b[0;36mrdheader\u001b[0;34m(record_name, pb_dir, rd_segments)\u001b[0m\n\u001b[1;32m    992\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m     \u001b[0;31m# Get fields from record line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m     \u001b[0mrecord_fields\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_header\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_record_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader_lines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m     \u001b[0;31m# Single segment header - Process signal specification lines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/wfdb/io/_header.py\u001b[0m in \u001b[0;36m_parse_record_line\u001b[0;34m(record_line)\u001b[0m\n\u001b[1;32m    744\u001b[0m      \u001b[0mrecord_fields\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'counter_freq'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord_fields\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'base_counter'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m      \u001b[0mrecord_fields\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sig_len'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord_fields\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'base_time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 746\u001b[0;31m      record_fields['base_date']) = re.findall(_rx_record, record_line)[0]\n\u001b[0m\u001b[1;32m    747\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfield\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mRECORD_SPECS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "wfdb.rdrecord(\"./data/Test/110\").__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
