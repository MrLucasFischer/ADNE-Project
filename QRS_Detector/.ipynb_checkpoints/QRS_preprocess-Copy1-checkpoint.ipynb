{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QRS training data Preprocessor\n",
    "\n",
    "This is just a a preprocessor ... (melhorar esta frase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wfdb\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading one of the training data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the channels of interest\n",
    "signal, info = wfdb.rdsamp(\"./data/Training/I17\", channel_names = [\"II\", \"V1\"])\n",
    "\n",
    "# Reading the annotations\n",
    "annotations = wfdb.rdann(\"./data/Training/I17\", \"atr\")\n",
    "symbol_positions = annotations.sample\n",
    "symbol_list = annotations.symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fs': 257,\n",
       " 'sig_len': 462600,\n",
       " 'n_sig': 2,\n",
       " 'base_date': None,\n",
       " 'base_time': None,\n",
       " 'units': ['mV', 'mV'],\n",
       " 'sig_name': ['II', 'V1'],\n",
       " 'comments': ['<age>: 64 <sex>: M <diagnoses> Transient ischemic attack',\n",
       "  'patient 8',\n",
       "  'bradycardia, PVCs, right bundle branch block,']}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ver aqui a frequÃªncia de samplagem para os dados de treino e teste\n",
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering out all the lines that do not have a QRS symbol\n",
    "\n",
    "qrs_symbs = ['N','L','R','B','A','a','J','S','V','r','F','e','j', 'n', 'E', '/', 'f', 'Q',' ?']\n",
    "\n",
    "qrs_symbol_positions = [symbol_positions[idx] for idx, symb in enumerate(symbol_list) if symb in qrs_symbs]\n",
    "\n",
    "# Filter negative symbol positions\n",
    "qrs_symbol_positions = [item for item in qrs_symbol_positions if item >= 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to build target vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auxiliary function\n",
    "def parabola(a,n,r):\n",
    "    \"\"\"\n",
    "    Creates a parabola around the position of a spike specified in 'a'\n",
    "    Params:\n",
    "        a - A vector specifying peak positions\n",
    "        n - The length of the target vector to generate\n",
    "        r - The radius of the parabola\n",
    "    \"\"\"\n",
    "    assert n>2*r\n",
    "    y = np.zeros(n, dtype = np.float32)\n",
    "    x = np.array(range(2,2*r+1))\n",
    "    for i in a:\n",
    "        if i > r-1 and i <= n-r:\n",
    "            y[i-r+1:i+r] = ((r+1)**2-(x-r-1)**2)/(r+1)**2\n",
    "        elif i < r:\n",
    "            y[:i+r] = ((r+1)**2-(x[r-i-1:]-r-1)**2)/(r+1)**2\n",
    "        elif i<n:\n",
    "            y[i-r+1:] = ((r+1)**2-(x[:r-1+(n-i)]-r-1)**2)/(r+1)**2\n",
    "    return y\n",
    "\n",
    "target_vec = parabola(qrs_symbol_positions, len(signal), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read of the test data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-94f4a56b2894>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Reading the channels of interest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_signal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwfdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdsamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./data/Test/I01\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Reading the annotations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_annotations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwfdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdann\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./data/Test/I01\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"atr\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/wfdb/io/record.py\u001b[0m in \u001b[0;36mrdsamp\u001b[0;34m(record_name, sampfrom, sampto, channels, pb_dir, channel_names, warn_empty)\u001b[0m\n\u001b[1;32m   1392\u001b[0m                       \u001b[0msampto\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msampto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphysical\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1393\u001b[0m                       \u001b[0mpb_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpb_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm2s\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannel_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchannel_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1394\u001b[0;31m                       warn_empty=warn_empty)\n\u001b[0m\u001b[1;32m   1395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1396\u001b[0m     \u001b[0msignals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp_signal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/wfdb/io/record.py\u001b[0m in \u001b[0;36mrdrecord\u001b[0;34m(record_name, sampfrom, sampto, channels, physical, pb_dir, m2s, smooth_frames, ignore_skew, return_res, force_channels, channel_names, warn_empty)\u001b[0m\n\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m     \u001b[0;31m# Read the header fields\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m     \u001b[0mrecord\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrdheader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpb_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpb_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrd_segments\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m     \u001b[0;31m# Set defaults for sampto and channels input variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/wfdb/io/record.py\u001b[0m in \u001b[0;36mrdheader\u001b[0;34m(record_name, pb_dir, rd_segments)\u001b[0m\n\u001b[1;32m    992\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m     \u001b[0;31m# Get fields from record line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m     \u001b[0mrecord_fields\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_header\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_record_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader_lines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m     \u001b[0;31m# Single segment header - Process signal specification lines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/wfdb/io/_header.py\u001b[0m in \u001b[0;36m_parse_record_line\u001b[0;34m(record_line)\u001b[0m\n\u001b[1;32m    744\u001b[0m      \u001b[0mrecord_fields\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'counter_freq'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord_fields\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'base_counter'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m      \u001b[0mrecord_fields\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sig_len'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord_fields\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'base_time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 746\u001b[0;31m      record_fields['base_date']) = re.findall(_rx_record, record_line)[0]\n\u001b[0m\u001b[1;32m    747\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfield\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mRECORD_SPECS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Reading the channels of interest\n",
    "test_signal, test_info = wfdb.rdsamp(\"./data/Test/I01\")\n",
    "\n",
    "# Reading the annotations\n",
    "test_annotations = wfdb.rdann(\"./data/Test/I01\", \"atr\")\n",
    "test_symbol_positions = test_annotations.sample\n",
    "test_symbol_list = test_annotations.symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess all test data files and save them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess all training files and save them with pickle\n",
    "import os\n",
    "import fnmatch\n",
    "\n",
    "# Iterate over all training files\n",
    "path = \"./data/Training/\"\n",
    "\n",
    "my_list = os.listdir(path)\n",
    "\n",
    "files = fnmatch.filter(my_list, '*.dat')\n",
    "#print(files)\n",
    "#print(len(files))\n",
    "\n",
    "for f in files:\n",
    "    data_name = f[:-4]\n",
    "    f_path = path + data_name\n",
    "    print(f_path)\n",
    "    # Reading the channels of interest\n",
    "    signal, info = wfdb.rdsamp(f_path, channel_names = [\"II\", \"V1\"])\n",
    "    # Reading the annotations\n",
    "    annotations = wfdb.rdann(f_path, \"atr\")\n",
    "    symbol_positions = annotations.sample\n",
    "    symbol_list = annotations.symbol\n",
    "    # Filtering out all the lines that do not have a QRS symbol\n",
    "    qrs_symbs = ['N','L','R','B','A','a','J','S','V','r','F','e','j', 'n', 'E', '/', 'f', 'Q',' ?']\n",
    "    qrs_symbol_positions = [symbol_positions[idx] for idx, symb in enumerate(symbol_list) if symb in qrs_symbs]\n",
    "    # Some positions are negative values, which does not make sense so we are filtering these negative values out\n",
    "    qrs_symbol_positions = [item for item in qrs_symbol_positions if item >= 0]\n",
    "    target_len = len(signal)\n",
    "    target_vec = parabola(qrs_symbol_positions, target_len, 3)\n",
    "    #print(len(signal))\n",
    "    #print(signal.shape)\n",
    "    # Build dictionary with features and target\n",
    "    #data2save = {\n",
    "    #    features: signal,\n",
    "    #    label: target_vec\n",
    "    #}\n",
    "    # Save preprocessed data with pickle\n",
    "    \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## VER COMO FAZER ISTO DO PICKLE\n",
    "#thing_to_save = {\n",
    "#    features: signal1 + signal2,\n",
    "#    label: target_vec\n",
    "#}\n",
    "\n",
    "#pkl.dump(thing_to_save)\n",
    "\n",
    "#pickle_out = open(\"dict.pickle\")\n",
    "#pickle.dump(thing_to_save, pickle_out)\n",
    "#pickle_out.close()\n",
    "\n",
    "dict_ = pkl.load(\"./things_to_load\")\n",
    "dict[\"features\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
