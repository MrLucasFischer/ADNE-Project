{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "QRS_Detector_collab.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7GJ9TLwzVSj",
        "colab_type": "text"
      },
      "source": [
        "# QRS Detector\n",
        "\n",
        "This notebook implements the actual QRS Detector. In this notebook there are two networks present, a fully conected feed forward network and a recurrent network, with the aim of comparing the two models and verifying which is more indicated for the type of data we have"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhmQIcyWzhNI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# importing required libraries\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle as pkl\n",
        "import random\n",
        "import math\n",
        "\n",
        "#!pip install wfdb\n",
        "import wfdb\n",
        "from wfdb.processing import find_local_peaks\n",
        "from wfdb.processing import compare_annotations"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jId_h31027mB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "#drive.mount('/content/drive/')\n",
        "from glob import glob"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1CJ9K5821yC",
        "colab_type": "code",
        "outputId": "9af76108-0627-43b8-cbec-ebf266f7fbed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "!ls drive/'My Drive'/'Colab Notebooks'/processed_data\n",
        "main_path = 'drive/My Drive/Colab Notebooks/processed_data/'\n",
        "weights_path = 'drive/My Drive/Colab Notebooks/network_weights/'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test  Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVBz9RZmzmB4",
        "colab_type": "text"
      },
      "source": [
        "## Sampling Function\n",
        "\n",
        "The objective is to retrieve a random cropping of both the signal and the target from all files specified for the training/validation set. This helps us have a more well-versed dataset for training and validating our models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSfAr_ABzq7s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# auxiliary function\n",
        "# extracts from a long np-array (2-rows) a (2-rows)-random segment with a fixed length (seqL*ninputs)\n",
        "def selectFrom1ecg(ecgBdata, seqL, ninputs, feed_forward = True, training = True, testing = False):\n",
        "    \"\"\"\n",
        "    x: An array with vairous files, channels and examples\n",
        "    seqL:  number of timesteps to be used in recurrent nn\n",
        "    ninput : is number of inputs in each timestep\n",
        "    file_indexes: A list of the file indexes for training or validation set\n",
        "    \"\"\"\n",
        "    segmentL  = seqL * ninputs\n",
        "    numChan = 3\n",
        "    \n",
        "    if(training):\n",
        "        random_file_idx = random.randint(0, 57)\n",
        "    else:\n",
        "        random_file_idx = random.randint(0, 9)\n",
        "    \n",
        "    if(testing):\n",
        "        random_file_idx = random.randint(0, 48)\n",
        "    \n",
        "    inpOutSegment = tf.random_crop(ecgBdata[random_file_idx],[numChan, segmentL])\n",
        "\n",
        "    \n",
        "    if(feed_forward):\n",
        "        channelII = inpOutSegment[0,:]\n",
        "        channelV1 = inpOutSegment[1,:]\n",
        "        target = inpOutSegment[2,:]\n",
        "        inputs = tf.concat((channelII, channelV1), axis = -1)\n",
        "        return inputs,target\n",
        "    else:\n",
        "        transposed = tf.transpose(inpOutSegment)\n",
        "        \n",
        "        inputs = transposed[:, :-1]\n",
        "        target = transposed[:, -1]\n",
        "        inputs = tf.reshape(inputs, (seqL, -1))\n",
        "        \n",
        "        # We need to re-transpose the target to turn int back into a one-row vector\n",
        "        target = tf.transpose(target)\n",
        "                \n",
        "        return inputs, target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxL8mgKIzuB7",
        "colab_type": "text"
      },
      "source": [
        "## Dataset array creation\n",
        "\n",
        "In this section we create the main dataset array containing all the training files. Each file has two input signals (channelII and channelV1) and a target signal."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDltqghDzu9y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_array = []\n",
        "\n",
        "files_not_to_read = [4,17,35,44,57,72,74]\n",
        "index_counter = 0\n",
        "for i in range(1, 76):\n",
        "    \n",
        "    if i not in files_not_to_read:\n",
        "        file_path = f\"Training/I{i:02}\"\n",
        "        file_path = main_path + file_path\n",
        "        file_data = pkl.load(open(file_path, \"rb\"))        \n",
        "        index_counter = index_counter + 1\n",
        "        \n",
        "        info = [file_data[\"channelII\"], file_data[\"channelV1\"], file_data[\"label\"]]\n",
        "        info = np.array(info)\n",
        "        info = info.astype(np.float32)\n",
        "        dataset_array.append(info)\n",
        "\n",
        "ecgs_array = np.array(dataset_array)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fu0bgq8Bz4P_",
        "colab_type": "text"
      },
      "source": [
        "## Test dataset array creation\n",
        "\n",
        "In this section we create the test dataset array containing all the test files. Each file has two input signals (\"MLII\",\"V1\", which correspond to signals \"II\" and \"V1\" in the training dataset) and a target signal."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NucVTffzz45Z",
        "colab_type": "code",
        "outputId": "e17f466c-f855-431a-86b3-1c6ec8c7f25a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "test_dataset_array = []\n",
        "\n",
        "files_not_to_read = [110, 120, 204, 206, 211, 216, 218, 229]\n",
        "files_not_to_read = files_not_to_read + list(range(125,200)) + list(range(224,228))\n",
        "\n",
        "index_counter = 0\n",
        "for i in range(100, 235):\n",
        "    \n",
        "    if i not in files_not_to_read:\n",
        "        file_path = f\"Test/{i}\"\n",
        "        file_path = main_path + file_path\n",
        "        file_data = pkl.load(open(file_path, \"rb\"))        \n",
        "        index_counter = index_counter + 1\n",
        "        \n",
        "        info = [file_data[\"channelII\"], file_data[\"channelV1\"], file_data[\"label\"]]\n",
        "        info = np.array(info)\n",
        "        info = info.astype(np.float32)\n",
        "        test_dataset_array.append(info)\n",
        "\n",
        "test_ecgs_array = np.array(test_dataset_array)\n",
        "\n",
        "# Test dataset length is not a multiple of 2*ninputs*seqL(rnn) which causes problems when we want to\n",
        "# transpose the data as before, so we discard the last 2000 points \n",
        "# The test dataset will then have the same length as the training dataset\n",
        "lenRecords = test_ecgs_array.shape[2]\n",
        "new_length = int(math.floor(lenRecords/5400))*5400\n",
        "test_ecgs_array = test_ecgs_array[:,:,:new_length]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "650000\n",
            "648000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZgCJQX161SF",
        "colab_type": "code",
        "outputId": "da86473e-cb4d-4e2a-deb9-433034d07bed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        }
      },
      "source": [
        "# number of examples\n",
        "N = ecgs_array.shape[2]\n",
        "\n",
        "# Sampling frequency\n",
        "fs = 360\n",
        "\n",
        "# For each timestep we give ninputs\n",
        "ninputs = int(0.2*fs)\n",
        "\n",
        "# Sequence length (number of timesteps)\n",
        "seqL = int((5 * 360)/ninputs) # Using a 5 second window sequence\n",
        "\n",
        "print('ninputs = ',ninputs)\n",
        "print('seqL = ',seqL)\n",
        "print('ninputs*seqL = ',ninputs*seqL)\n",
        "\n",
        "# training data for feed forward network\n",
        "# Create efficient training sequences\n",
        "trainData = tf.data.Dataset.from_tensors(ecgs_array[:len(ecgs_array) - 10, :, :])\n",
        "trainData = trainData.map(lambda x:  selectFrom1ecg(x, seqL, ninputs, training = True))\n",
        "trainData = trainData.repeat()  # Repeat the input indefinitely.\n",
        "batchSize = 8\n",
        "trainData = trainData.batch(batchSize)\n",
        "\n",
        "valData = tf.data.Dataset.from_tensors(ecgs_array[len(ecgs_array) - 10:, :, :])\n",
        "valData = valData.map(lambda x:  selectFrom1ecg(x, seqL, ninputs, training = False))\n",
        "valData = valData.repeat()  # Repeat the input indefinitely.\n",
        "batchSize = 8\n",
        "valData = valData.batch(batchSize)\n",
        "\n",
        "# test data for feed forward network (here we don't need to leave out the 10 files)\n",
        "testData = tf.data.Dataset.from_tensors(test_ecgs_array)\n",
        "testData = testData.map(lambda x:  selectFrom1ecg(x, seqL, ninputs, training = False, testing = True))\n",
        "testData = testData.repeat()  # Repeat the input indefinitely.\n",
        "batchSize = 8\n",
        "testData = testData.batch(batchSize)\n",
        "\n",
        "\n",
        "# Creating Training and Validation datasets with the correct shape for a Recurrent neural network\n",
        "# The sequence length for the recurrent neural network can be about 3 times greater than for the feed\n",
        "# forward neural net\n",
        "seql_rnn = 3 * seqL\n",
        "\n",
        "print('ninputs*seqL(rnn) = ',ninputs*seql_rnn)\n",
        "\n",
        "trainData_rnn = tf.data.Dataset.from_tensors(ecgs_array[:len(ecgs_array) - 10, :, :])\n",
        "trainData_rnn = trainData_rnn.map(lambda x:  selectFrom1ecg(x, seql_rnn, ninputs, training = True, feed_forward = False))\n",
        "trainData_rnn = trainData_rnn.repeat()  # Repeat the input indefinitely.\n",
        "batchSize_rnn = 8\n",
        "trainData_rnn = trainData_rnn.batch(batchSize_rnn)\n",
        "\n",
        "valData_rnn = tf.data.Dataset.from_tensors(ecgs_array[len(ecgs_array) - 10:, :, :])\n",
        "valData_rnn = valData_rnn.map(lambda x:  selectFrom1ecg(x, seql_rnn, ninputs, training = False, feed_forward = False))\n",
        "valData_rnn = valData_rnn.repeat()  # Repeat the input indefinitely.\n",
        "batchSize_rnn = 8\n",
        "valData_rnn = valData_rnn.batch(batchSize_rnn)\n",
        "\n",
        "\n",
        "# test data for feed forward network (here we don't need to leave out the 10 files)\n",
        "testData_rnn = tf.data.Dataset.from_tensors(test_ecgs_array)\n",
        "testData_rnn = testData_rnn.map(lambda x:  selectFrom1ecg(x, seql_rnn, ninputs, training = False, feed_forward = False, testing = True))\n",
        "testData_rnn = testData_rnn.repeat()  # Repeat the input indefinitely.\n",
        "batchSize = 8\n",
        "testData_rnn = testData_rnn.batch(batchSize)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ninputs =  72\n",
            "seqL =  25\n",
            "ninputs*seqL =  1800\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "ninputs*seqL(rnn) =  5400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDLVG3AG7iAh",
        "colab_type": "text"
      },
      "source": [
        "# Recurrent neural network\n",
        "\n",
        "In this subsection we define the architecture for the RNN. We are using 4 LSTM layers with GPU support.\n",
        "After fitting our RNN we save the model weights to be able to reuse them without retraining the network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOVz39jL7k93",
        "colab_type": "code",
        "outputId": "b0666d25-bdd1-4109-f63e-d2da1c1b2e2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "numLstmUnits = 320\n",
        "\n",
        "rnnModel = tf.keras.Sequential()\n",
        "rnnModel.add(layers.CuDNNLSTM(units=numLstmUnits, return_sequences=True, input_shape = (seql_rnn, 2 * ninputs)))         \n",
        "rnnModel.add(layers.CuDNNLSTM(units=numLstmUnits, return_sequences=True))\n",
        "rnnModel.add(layers.CuDNNLSTM(units=numLstmUnits, return_sequences=True))         \n",
        "rnnModel.add(layers.CuDNNLSTM(units=numLstmUnits, return_sequences=True))\n",
        "rnnModel.add(layers.TimeDistributed(layers.Dense(ninputs)))\n",
        "rnnModel.add(layers.Reshape((seql_rnn * ninputs, )))\n",
        "\n",
        "rnnModel.compile(optimizer=tf.train.RMSPropOptimizer(0.001), loss='MSE',metrics=['mae'])\n",
        "\n",
        "#rnnModel.fit(trainData_rnn,  epochs=10, steps_per_epoch=1000, validation_data=valData_rnn, validation_steps=100)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0116 - mean_absolute_error: 0.0251 - val_loss: 0.0113 - val_mean_absolute_error: 0.0278\n",
            "Epoch 2/10\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0111 - mean_absolute_error: 0.0293 - val_loss: 0.0114 - val_mean_absolute_error: 0.0531\n",
            "Epoch 3/10\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0076 - mean_absolute_error: 0.0343 - val_loss: 0.0088 - val_mean_absolute_error: 0.0397\n",
            "Epoch 4/10\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0031 - mean_absolute_error: 0.0219 - val_loss: 0.0115 - val_mean_absolute_error: 0.0320\n",
            "Epoch 5/10\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0019 - mean_absolute_error: 0.0141 - val_loss: 0.0117 - val_mean_absolute_error: 0.0277\n",
            "Epoch 6/10\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0018 - mean_absolute_error: 0.0118 - val_loss: 0.0115 - val_mean_absolute_error: 0.0260\n",
            "Epoch 7/10\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0017 - mean_absolute_error: 0.0108 - val_loss: 0.0117 - val_mean_absolute_error: 0.0251\n",
            "Epoch 8/10\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0017 - mean_absolute_error: 0.0103 - val_loss: 0.0114 - val_mean_absolute_error: 0.0239\n",
            "Epoch 9/10\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0017 - mean_absolute_error: 0.0098 - val_loss: 0.0112 - val_mean_absolute_error: 0.0236\n",
            "Epoch 10/10\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0016 - mean_absolute_error: 0.0096 - val_loss: 0.0113 - val_mean_absolute_error: 0.0230\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fbd219e2898>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOWmzZLOGLzl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Saving the network weights\n",
        "weights_file_path_7layers = weights_path + 'RNN_weights_7layers.h5'\n",
        "weights_file_path = weights_path + 'RNN_weights.h5'\n",
        "rnnModel.save_weights(weights_file_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgoIa41xZij8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rnnModel.load_weights(weights_file_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGzZlhTEayMv",
        "colab_type": "text"
      },
      "source": [
        "## Predict - RNN\n",
        "\n",
        "This section is dedicated to generate the predictions of our RNN model. We first consider ten batches and obtain the predictions for them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4y9E6NK3bsY9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#output = rnnModel.predict(testData_rnn,steps=1000)\n",
        "#print(output.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EgZjsXrGhre",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_preds_targets(tf_dataset,model):\n",
        "  predictions = []\n",
        "  targets = []\n",
        "  nbatches = 10\n",
        "\n",
        "  try:\n",
        "    iterator = tf_dataset.make_initializable_iterator()\n",
        "    next_element = iterator.get_next()\n",
        "\n",
        "    for i in range(nbatches):\n",
        "      with tf.Session() as sess:\n",
        "        sess.run(iterator.initializer)\n",
        "        inp, targ = sess.run(next_element)\n",
        "        targets.append(targ)\n",
        "        print(f\"Getting batch {i}\")\n",
        "      output = model.predict(inp)\n",
        "      predictions.append(output)\n",
        "\n",
        "  except:\n",
        "    print('something wrong!')\n",
        "    pass\n",
        "  \n",
        "  return predictions, targets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIeGeN6SltXM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "d1fdb4bc-b7a4-4cb4-d40b-6203967b142e"
      },
      "source": [
        "predictions, targets = get_preds_targets(testData_rnn, rnnModel)\n",
        "targets1D = np.reshape(targets,(nbatches*batchSize_rnn*seql_rnn * ninputs))\n",
        "predictions1D = np.reshape(predictions,(nbatches*batchSize_rnn*seql_rnn * ninputs))"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Getting batch 0\n",
            "Getting batch 1\n",
            "Getting batch 2\n",
            "Getting batch 3\n",
            "Getting batch 4\n",
            "Getting batch 5\n",
            "Getting batch 6\n",
            "Getting batch 7\n",
            "Getting batch 8\n",
            "Getting batch 9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Azevr0csK32",
        "colab_type": "text"
      },
      "source": [
        "## Postprocessing\n",
        "\n",
        "The predictions of the RNN network are processed to eliminate false peaks (oscillations below a certain threshold). We then use the function find_local_peaks to obtain the peak positions. However, since this function gives false peaks in regions where the signal is flat, we filter its result with the same threshold as before."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9-FURnHt27t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_peaks(predictions1D,targets1D):\n",
        "  # First use a threshold to eliminate some smaller peaks\n",
        "  thresh = 0.5\n",
        "  peaks = np.where(predictions1D>thresh, predictions1D, 0)\n",
        "\n",
        "  # Find local peaks in filtered predictions\n",
        "  peak_locs = find_local_peaks(peaks,8)\n",
        "\n",
        "  # Filter peak locations with condition that value of signal there must be \n",
        "  peak_locs_above_th = [p for p in peak_locs if peaks[p] > thresh]\n",
        "\n",
        "  peaks_targets1D = np.where(targets1D>thresh, targets1D, 0)\n",
        "  # Find local peaks in filtered predictions\n",
        "  targets_peak_locs = find_local_peaks(peaks_targets1D,8)\n",
        "  targets_peak_locs_above_th = [p for p in targets_peak_locs if peaks_targets1D[p] > thresh]\n",
        "\n",
        "  targets_peak_locs_above_th = np.array(targets_peak_locs_above_th)\n",
        "  peak_locs_above_th = np.array(peak_locs_above_th)\n",
        "  \n",
        "  return peak_locs_above_th, targets_peak_locs_above_th"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XtHzwNgoNc-",
        "colab_type": "text"
      },
      "source": [
        "Finding peak indexes for plotting purposes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAckmAeLhvDc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "f57f3104-60c9-4e5b-b5d1-9bac1d26cd7f"
      },
      "source": [
        "peak_locs_above_th, targets_peak_locs_above_th = get_peaks(predictions1D,targets1D)\n",
        "peak_locs_above_th"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 49553,  52696,  74591,  78528,  78680,  83058,  84919,  85622,\n",
              "       131358, 133343, 136519, 137218, 175327, 177237, 184278, 208469,\n",
              "       208625, 210629, 223231, 225196, 238926, 241229, 249631, 255811,\n",
              "       258954, 262479, 316958, 350927, 375830, 389557, 391548, 393448,\n",
              "       415551])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jupyk4GwQWm",
        "colab_type": "code",
        "outputId": "955a8f71-02cf-48d1-dd19-3bb6ee3040e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        }
      },
      "source": [
        "t = range(nbatches*batchSize_rnn*seql_rnn*ninputs)\n",
        "plt.plot(t[49000:54000],predictions1D[49000:54000]-2,'b',t[49000:54000],peaks[49000:54000],'g')"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fbd06380908>,\n",
              " <matplotlib.lines.Line2D at 0x7fbd06380a58>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SMVp1dPoYHN",
        "colab_type": "text"
      },
      "source": [
        "## Compare predicted peaks with annotations\n",
        "\n",
        "We now compare our predicted peaks (after postprocessing) with the labelled peaks to determine the number of peaks correctly classified by our network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i65ldSjWM4-K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "7e4e94e4-f4a6-4880-c00c-f58ff6a5cd97"
      },
      "source": [
        "comparitor = compare_annotations(targets_peak_locs_above_th, peak_locs_above_th, 5, signal=None)\n",
        "comparitor.print_summary()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1249 reference annotations, 33 test annotations\n",
            "\n",
            "True Positives (matched samples): 31\n",
            "False Positives (unmatched test samples: 2\n",
            "False Negatives (unmatched reference samples): 1218\n",
            "\n",
            "Specificity: 0.0248 (31/1249)\n",
            "Positive Predictivity: 0.9394 (31/33)\n",
            "False Positive Rate: 0.0606 (2/33)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0hloy5W7Dxe",
        "colab_type": "text"
      },
      "source": [
        "# Feedforward network\n",
        "\n",
        "The architecture of the Feedforward network is designed below, similarly to what was done for the RNN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uvHOwSd7HI3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "2f92cd58-21b7-4ab2-9616-9f4e95a051df"
      },
      "source": [
        "ffwdModel = tf.keras.Sequential()\n",
        "ffwdModel.add(layers.Dense(64, activation='relu',input_shape=(2*seqL*ninputs,)))\n",
        "ffwdModel.add(layers.Dense(64, activation='relu'))\n",
        "ffwdModel.add(layers.Dense(64, activation='relu'))\n",
        "ffwdModel.add(layers.Dense(seqL*ninputs))\n",
        "\n",
        "ffwdModel.compile(optimizer=tf.train.RMSPropOptimizer(0.001), loss='MSE',metrics=['mae'])\n",
        "ffwdModel.fit(trainData,  epochs=15, steps_per_epoch=1000, validation_data=valData, validation_steps=100)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0128 - mean_absolute_error: 0.0272 - val_loss: 0.0100 - val_mean_absolute_error: 0.0260\n",
            "Epoch 2/15\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0126 - mean_absolute_error: 0.0283 - val_loss: 0.0102 - val_mean_absolute_error: 0.0325\n",
            "Epoch 3/15\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0124 - mean_absolute_error: 0.0308 - val_loss: 0.0102 - val_mean_absolute_error: 0.0352\n",
            "Epoch 4/15\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0122 - mean_absolute_error: 0.0316 - val_loss: 0.0102 - val_mean_absolute_error: 0.0351\n",
            "Epoch 5/15\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0123 - mean_absolute_error: 0.0317 - val_loss: 0.0102 - val_mean_absolute_error: 0.0338\n",
            "Epoch 6/15\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0122 - mean_absolute_error: 0.0315 - val_loss: 0.0104 - val_mean_absolute_error: 0.0352\n",
            "Epoch 7/15\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0122 - mean_absolute_error: 0.0312 - val_loss: 0.0105 - val_mean_absolute_error: 0.0361\n",
            "Epoch 8/15\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0123 - mean_absolute_error: 0.0310 - val_loss: 0.0106 - val_mean_absolute_error: 0.0384\n",
            "Epoch 9/15\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0122 - mean_absolute_error: 0.0307 - val_loss: 0.0106 - val_mean_absolute_error: 0.0350\n",
            "Epoch 10/15\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0122 - mean_absolute_error: 0.0306 - val_loss: 0.0106 - val_mean_absolute_error: 0.0356\n",
            "Epoch 11/15\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0122 - mean_absolute_error: 0.0303 - val_loss: 0.0107 - val_mean_absolute_error: 0.0394\n",
            "Epoch 12/15\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0122 - mean_absolute_error: 0.0301 - val_loss: 0.0105 - val_mean_absolute_error: 0.0333\n",
            "Epoch 13/15\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0122 - mean_absolute_error: 0.0300 - val_loss: 0.0107 - val_mean_absolute_error: 0.0408\n",
            "Epoch 14/15\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0121 - mean_absolute_error: 0.0298 - val_loss: 0.0106 - val_mean_absolute_error: 0.0377\n",
            "Epoch 15/15\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0121 - mean_absolute_error: 0.0297 - val_loss: 0.0105 - val_mean_absolute_error: 0.0380\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fbc9f3a4be0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsLEr85nSfUh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Saving the network weights\n",
        "ffwd_weights_file_path = weights_path + 'FFWD_weights.h5'\n",
        "ffwdModel.save_weights(ffwd_weights_file_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZoXNrZlS94a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ffwdModel.load_weights(ffwd_weights_file_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crBNa3GNTk1s",
        "colab_type": "text"
      },
      "source": [
        "## Predict - FFWD\n",
        "\n",
        "This process is analog to what was done for the RNN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ef31yOx1mPe4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "f914e40a-f709-46fe-bbf5-64eb9ae3b2e7"
      },
      "source": [
        "ffwd_predictions, ffwd_targets = get_preds_targets(testData, ffwdModel)\n",
        "ffwd_targets1D = np.reshape(ffwd_targets,(nbatches*batchSize*seqL * ninputs))\n",
        "ffwd_predictions1D = np.reshape(ffwd_predictions,(nbatches*batchSize*seqL * ninputs))"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Getting batch 0\n",
            "Getting batch 1\n",
            "Getting batch 2\n",
            "Getting batch 3\n",
            "Getting batch 4\n",
            "Getting batch 5\n",
            "Getting batch 6\n",
            "Getting batch 7\n",
            "Getting batch 8\n",
            "Getting batch 9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtdPqUMoUrLu",
        "colab_type": "text"
      },
      "source": [
        "## Posprocessing\n",
        "\n",
        "Postprocessing of the predicted peaks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wo56cKuCk9Ys",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "617647f9-af46-4157-9067-69e4d94fc077"
      },
      "source": [
        "ffwd_peak_locs_above_th, ffwd_targets_peak_locs_above_th = get_peaks(ffwd_predictions1D,ffwd_targets1D)\n",
        "ffwd_peak_locs_above_th"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([63253, 72253])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2LC5f23WQY3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "outputId": "2bba24bb-0763-43e8-e575-9359c265be77"
      },
      "source": [
        "ffwd_t = range(nbatches*batchSize*seqL*ninputs)\n",
        "plt.plot(ffwd_t[23000:60000],ffwd_predictions1D[23000:60000]-2,'b',ffwd_t[23000:60000],ffwd_peaks[23000:60000],'g')"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fbc802739b0>,\n",
              " <matplotlib.lines.Line2D at 0x7fbc80273b00>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nABGRSCkBiIhE6v8DvlLRY3QBsmUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gio1ysGZpNWA",
        "colab_type": "text"
      },
      "source": [
        "## Compare predicted peaks with annotations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7LO1AsVVrWg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "1e3a67da-cbfc-49dd-eaa4-4bb625194d3c"
      },
      "source": [
        "ffwd_comparitor = compare_annotations(ffwd_targets_peak_locs_above_th, ffwd_peak_locs_above_th, 5, signal=None)\n",
        "ffwd_comparitor.print_summary()"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "393 reference annotations, 2 test annotations\n",
            "\n",
            "True Positives (matched samples): 2\n",
            "False Positives (unmatched test samples: 0\n",
            "False Negatives (unmatched reference samples): 391\n",
            "\n",
            "Specificity: 0.0051 (2/393)\n",
            "Positive Predictivity: 1.0000 (2/2)\n",
            "False Positive Rate: 0.0000 (0/2)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}