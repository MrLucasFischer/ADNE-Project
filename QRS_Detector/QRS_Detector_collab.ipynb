{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "QRS_Detector_collab.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7GJ9TLwzVSj",
        "colab_type": "text"
      },
      "source": [
        "# QRS Detector\n",
        "\n",
        "This notebook implements the actual QRS Detector. In this notebook there are two networks present, a fully conected feed forward network and a recurrent network, with the aim of comparing the two models and verifying which is more indicated for the type of data we have"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhmQIcyWzhNI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# importing required libraries\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle as pkl\n",
        "import random\n",
        "import math\n",
        "\n",
        "#!pip install wfdb\n",
        "import wfdb\n",
        "from wfdb.processing import find_local_peaks\n",
        "from wfdb.processing import compare_annotations"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jId_h31027mB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "54a7b008-546e-4262-b248-63e6139b0dba"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "from glob import glob"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szVqmJnava5J",
        "colab_type": "text"
      },
      "source": [
        "This part describes the location of the data files. The processed data files shoud be placed in a folder inside google Drive and the path for that folder shoud be specified in `main_path`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1CJ9K5821yC",
        "colab_type": "code",
        "outputId": "0733eb7f-e22f-471d-b0c0-5ab4c6747438",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "!ls drive/'My Drive'/'Colab Notebooks'/processed_data\n",
        "main_path = 'drive/My Drive/Colab Notebooks/processed_data/'\n",
        "weights_path = 'drive/My Drive/Colab Notebooks/network_weights/'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test  Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVBz9RZmzmB4",
        "colab_type": "text"
      },
      "source": [
        "## Sampling Function\n",
        "\n",
        "The objective is to retrieve a random cropping of both the signal and the target from all files specified for the training/validation set. This helps us have a more well-versed dataset for training and validating our models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSfAr_ABzq7s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# auxiliary function\n",
        "# extracts from a long np-array (2-rows) a (2-rows)-random segment with a fixed length (seqL*ninputs)\n",
        "def selectFrom1ecg(ecgBdata, seqL, ninputs, feed_forward = True, training = True, testing = False):\n",
        "    \"\"\"\n",
        "    x: An array with vairous files, channels and examples\n",
        "    seqL:  number of timesteps to be used in recurrent nn\n",
        "    ninput : is number of inputs in each timestep\n",
        "    file_indexes: A list of the file indexes for training or validation set\n",
        "    \"\"\"\n",
        "    segmentL  = seqL * ninputs\n",
        "    numChan = 3\n",
        "    \n",
        "    if(training):\n",
        "        random_file_idx = random.randint(0, 57)\n",
        "    else:\n",
        "        random_file_idx = random.randint(0, 9)\n",
        "    \n",
        "    if(testing):\n",
        "        random_file_idx = random.randint(0, 48)\n",
        "    \n",
        "    inpOutSegment = tf.random_crop(ecgBdata[random_file_idx],[numChan, segmentL])\n",
        "\n",
        "    \n",
        "    if(feed_forward):\n",
        "        channelII = inpOutSegment[0,:]\n",
        "        channelV1 = inpOutSegment[1,:]\n",
        "        target = inpOutSegment[2,:]\n",
        "        inputs = tf.concat((channelII, channelV1), axis = -1)\n",
        "        return inputs,target\n",
        "    else:\n",
        "        transposed = tf.transpose(inpOutSegment)\n",
        "        \n",
        "        inputs = transposed[:, :-1]\n",
        "        target = transposed[:, -1]\n",
        "        inputs = tf.reshape(inputs, (seqL, -1))\n",
        "        \n",
        "        # We need to re-transpose the target to turn int back into a one-row vector\n",
        "        target = tf.transpose(target)\n",
        "                \n",
        "        return inputs, target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxL8mgKIzuB7",
        "colab_type": "text"
      },
      "source": [
        "## Dataset array creation\n",
        "\n",
        "In this section we create the main dataset array containing all the training files. Each file has two input signals (channelII and channelV1) and a target signal."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDltqghDzu9y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_array = []\n",
        "\n",
        "files_not_to_read = [4,17,35,44,57,72,74]\n",
        "index_counter = 0\n",
        "for i in range(1, 76):\n",
        "    \n",
        "    if i not in files_not_to_read:\n",
        "        file_path = f\"Training/I{i:02}\"\n",
        "        file_path = main_path + file_path\n",
        "        file_data = pkl.load(open(file_path, \"rb\"))        \n",
        "        index_counter = index_counter + 1\n",
        "        \n",
        "        info = [file_data[\"channelII\"], file_data[\"channelV1\"], file_data[\"label\"]]\n",
        "        info = np.array(info)\n",
        "        info = info.astype(np.float32)\n",
        "        dataset_array.append(info)\n",
        "\n",
        "ecgs_array = np.array(dataset_array)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ue13qeU2xFA8",
        "colab_type": "text"
      },
      "source": [
        "### Parameters for networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NENnHxrxDyN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "d3cca7e1-81bc-48ba-9a4c-4c7670cb57e5"
      },
      "source": [
        "# Sampling frequency\n",
        "fs = 360\n",
        "\n",
        "# For each timestep we give ninputs\n",
        "ninputs = int(0.2*fs)\n",
        "\n",
        "# Sequence length (number of timesteps)\n",
        "seqL = int((5 * 360)/ninputs) # Using a 5 second window sequence\n",
        "\n",
        "\n",
        "print('FFWD network parameters')\n",
        "print('ninputs = ',ninputs)\n",
        "print('seqL = ',seqL)\n",
        "print('ninputs*seqL = ',ninputs*seqL)\n",
        "\n",
        "seql_rnn = 3 * seqL\n",
        "\n",
        "print(\" \")\n",
        "print('RNN network parameters')\n",
        "print('ninputs = ',ninputs)\n",
        "print('seqL(rnn) = ',seql_rnn)\n",
        "print('ninputs*seqL(rnn) = ',ninputs*seql_rnn)\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FFWD network parameters\n",
            "ninputs =  72\n",
            "seqL =  25\n",
            "ninputs*seqL =  1800\n",
            " \n",
            "RNN network parameters\n",
            "ninputs =  72\n",
            "seqL(rnn) =  75\n",
            "ninputs*seqL(rnn) =  5400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fu0bgq8Bz4P_",
        "colab_type": "text"
      },
      "source": [
        "## Test dataset array creation\n",
        "\n",
        "In this section we create the test dataset array containing all the test files. Each file has two input signals (\"MLII\",\"V1\", which correspond to signals \"II\" and \"V1\" in the training dataset) and a target signal."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NucVTffzz45Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_dataset_array = []\n",
        "\n",
        "files_not_to_read = [110, 120, 204, 206, 211, 216, 218, 229]\n",
        "files_not_to_read = files_not_to_read + list(range(125,200)) + list(range(224,228))\n",
        "\n",
        "index_counter = 0\n",
        "for i in range(100, 235):\n",
        "    \n",
        "    if i not in files_not_to_read:\n",
        "        file_path = f\"Test/{i}\"\n",
        "        file_path = main_path + file_path\n",
        "        file_data = pkl.load(open(file_path, \"rb\"))        \n",
        "        index_counter = index_counter + 1\n",
        "        \n",
        "        info = [file_data[\"channelII\"], file_data[\"channelV1\"], file_data[\"label\"]]\n",
        "        info = np.array(info)\n",
        "        info = info.astype(np.float32)\n",
        "        test_dataset_array.append(info)\n",
        "\n",
        "test_ecgs_array = np.array(test_dataset_array)\n",
        "\n",
        "# Test dataset length is not a multiple of 2*ninputs*seqL(rnn) which causes problems when we want to\n",
        "# transpose the data as before, so we discard the last 2000 points \n",
        "# The test dataset will then have the same length as the training dataset\n",
        "lenRecords = test_ecgs_array.shape[2]\n",
        "new_length = int(math.floor(lenRecords/(ninputs*seql_rnn))*(ninputs*seql_rnn))\n",
        "test_ecgs_array = test_ecgs_array[:,:,:new_length]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZgCJQX161SF",
        "colab_type": "code",
        "outputId": "97d51ec6-6839-4959-9315-5f9f3ecde01c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "# number of examples\n",
        "N = ecgs_array.shape[2]\n",
        "\n",
        "# training data for feed forward network\n",
        "# Create efficient training sequences\n",
        "trainData = tf.data.Dataset.from_tensors(ecgs_array[:len(ecgs_array) - 10, :, :])\n",
        "trainData = trainData.map(lambda x:  selectFrom1ecg(x, seqL, ninputs, training = True))\n",
        "trainData = trainData.repeat()  # Repeat the input indefinitely.\n",
        "batchSize = 8\n",
        "trainData = trainData.batch(batchSize)\n",
        "\n",
        "valData = tf.data.Dataset.from_tensors(ecgs_array[len(ecgs_array) - 10:, :, :])\n",
        "valData = valData.map(lambda x:  selectFrom1ecg(x, seqL, ninputs, training = False))\n",
        "valData = valData.repeat()  # Repeat the input indefinitely.\n",
        "batchSize = 8\n",
        "valData = valData.batch(batchSize)\n",
        "\n",
        "# test data for feed forward network (here we don't need to leave out the 10 files)\n",
        "testData = tf.data.Dataset.from_tensors(test_ecgs_array)\n",
        "testData = testData.map(lambda x:  selectFrom1ecg(x, seqL, ninputs, training = False, testing = True))\n",
        "testData = testData.repeat()  # Repeat the input indefinitely.\n",
        "batchSize = 8\n",
        "testData = testData.batch(batchSize)\n",
        "\n",
        "\n",
        "# Creating Training and Validation datasets with the correct shape for a Recurrent neural network\n",
        "# The sequence length for the recurrent neural network can be about 3 times greater than for the feed\n",
        "# forward neural net\n",
        "\n",
        "\n",
        "trainData_rnn = tf.data.Dataset.from_tensors(ecgs_array[:len(ecgs_array) - 10, :, :])\n",
        "trainData_rnn = trainData_rnn.map(lambda x:  selectFrom1ecg(x, seql_rnn, ninputs, training = True, feed_forward = False))\n",
        "trainData_rnn = trainData_rnn.repeat()  # Repeat the input indefinitely.\n",
        "batchSize_rnn = 8\n",
        "trainData_rnn = trainData_rnn.batch(batchSize_rnn)\n",
        "\n",
        "valData_rnn = tf.data.Dataset.from_tensors(ecgs_array[len(ecgs_array) - 10:, :, :])\n",
        "valData_rnn = valData_rnn.map(lambda x:  selectFrom1ecg(x, seql_rnn, ninputs, training = False, feed_forward = False))\n",
        "valData_rnn = valData_rnn.repeat()  # Repeat the input indefinitely.\n",
        "batchSize_rnn = 8\n",
        "valData_rnn = valData_rnn.batch(batchSize_rnn)\n",
        "\n",
        "\n",
        "# test data for feed forward network (here we don't need to leave out the 10 files)\n",
        "testData_rnn = tf.data.Dataset.from_tensors(test_ecgs_array)\n",
        "testData_rnn = testData_rnn.map(lambda x:  selectFrom1ecg(x, seql_rnn, ninputs, training = False, feed_forward = False, testing = True))\n",
        "testData_rnn = testData_rnn.repeat()  # Repeat the input indefinitely.\n",
        "batchSize = 8\n",
        "testData_rnn = testData_rnn.batch(batchSize)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDLVG3AG7iAh",
        "colab_type": "text"
      },
      "source": [
        "# Recurrent neural network\n",
        "\n",
        "In this subsection we define the architecture for the RNN. We are using 4 LSTM layers with GPU support.\n",
        "After fitting our RNN we save the model weights to be able to reuse them without retraining the network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOVz39jL7k93",
        "colab_type": "code",
        "outputId": "8cb7f78b-739a-4276-a4f5-16208d24d6f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1020
        }
      },
      "source": [
        "numLstmUnits = 320\n",
        "\n",
        "rnnModel = tf.keras.Sequential()\n",
        "rnnModel.add(layers.CuDNNLSTM(units=numLstmUnits, return_sequences=True, input_shape = (seql_rnn, 2 * ninputs)))         \n",
        "rnnModel.add(layers.CuDNNLSTM(units=numLstmUnits, return_sequences=True))\n",
        "rnnModel.add(layers.CuDNNLSTM(units=numLstmUnits, return_sequences=True))         \n",
        "rnnModel.add(layers.CuDNNLSTM(units=numLstmUnits, return_sequences=True))\n",
        "rnnModel.add(layers.TimeDistributed(layers.Dense(ninputs)))\n",
        "rnnModel.add(layers.Reshape((seql_rnn * ninputs, )))\n",
        "\n",
        "rnnModel.compile(optimizer=tf.train.RMSPropOptimizer(0.001), loss='MSE',metrics=['mae'])\n",
        "\n",
        "#rnnModel.fit(trainData_rnn,  epochs=15, steps_per_epoch=1000, validation_data=valData_rnn, validation_steps=100)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/15\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0175 - mean_absolute_error: 0.0382 - val_loss: 0.0105 - val_mean_absolute_error: 0.0476\n",
            "Epoch 2/15\n",
            "1000/1000 [==============================] - 24s 24ms/step - loss: 0.0125 - mean_absolute_error: 0.0493 - val_loss: 0.0078 - val_mean_absolute_error: 0.0424\n",
            "Epoch 3/15\n",
            "1000/1000 [==============================] - 24s 24ms/step - loss: 0.0042 - mean_absolute_error: 0.0257 - val_loss: 0.0086 - val_mean_absolute_error: 0.0366\n",
            "Epoch 4/15\n",
            "1000/1000 [==============================] - 24s 24ms/step - loss: 0.0032 - mean_absolute_error: 0.0177 - val_loss: 0.0081 - val_mean_absolute_error: 0.0327\n",
            "Epoch 5/15\n",
            "1000/1000 [==============================] - 24s 24ms/step - loss: 0.0030 - mean_absolute_error: 0.0157 - val_loss: 0.0080 - val_mean_absolute_error: 0.0307\n",
            "Epoch 6/15\n",
            "1000/1000 [==============================] - 25s 25ms/step - loss: 0.0030 - mean_absolute_error: 0.0147 - val_loss: 0.0080 - val_mean_absolute_error: 0.0290\n",
            "Epoch 7/15\n",
            "1000/1000 [==============================] - 25s 25ms/step - loss: 0.0029 - mean_absolute_error: 0.0141 - val_loss: 0.0081 - val_mean_absolute_error: 0.0281\n",
            "Epoch 8/15\n",
            "1000/1000 [==============================] - 25s 25ms/step - loss: 0.0028 - mean_absolute_error: 0.0136 - val_loss: 0.0080 - val_mean_absolute_error: 0.0275\n",
            "Epoch 9/15\n",
            "1000/1000 [==============================] - 25s 25ms/step - loss: 0.0028 - mean_absolute_error: 0.0133 - val_loss: 0.0078 - val_mean_absolute_error: 0.0266\n",
            "Epoch 10/15\n",
            "1000/1000 [==============================] - 25s 25ms/step - loss: 0.0027 - mean_absolute_error: 0.0131 - val_loss: 0.0075 - val_mean_absolute_error: 0.0257\n",
            "Epoch 11/15\n",
            "1000/1000 [==============================] - 25s 25ms/step - loss: 0.0027 - mean_absolute_error: 0.0129 - val_loss: 0.0071 - val_mean_absolute_error: 0.0254\n",
            "Epoch 12/15\n",
            "1000/1000 [==============================] - 25s 25ms/step - loss: 0.0027 - mean_absolute_error: 0.0127 - val_loss: 0.0069 - val_mean_absolute_error: 0.0252\n",
            "Epoch 13/15\n",
            "1000/1000 [==============================] - 25s 25ms/step - loss: 0.0026 - mean_absolute_error: 0.0124 - val_loss: 0.0070 - val_mean_absolute_error: 0.0250\n",
            "Epoch 14/15\n",
            "1000/1000 [==============================] - 25s 25ms/step - loss: 0.0026 - mean_absolute_error: 0.0123 - val_loss: 0.0069 - val_mean_absolute_error: 0.0244\n",
            "Epoch 15/15\n",
            "1000/1000 [==============================] - 25s 25ms/step - loss: 0.0025 - mean_absolute_error: 0.0122 - val_loss: 0.0068 - val_mean_absolute_error: 0.0247\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff3fb6a2668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luhm5ivH-ywS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights_file_path_8layers = weights_path + 'RNN_weights_8layers.h5'\n",
        "weights_file_path = weights_path + 'RNN_weights.h5'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOWmzZLOGLzl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Saving the network weights\n",
        "rnnModel.save_weights(weights_file_path)\n",
        "#rnnModel.save_weights(weights_file_path_8layers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgoIa41xZij8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rnnModel.load_weights(weights_file_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGzZlhTEayMv",
        "colab_type": "text"
      },
      "source": [
        "## Predict - RNN\n",
        "\n",
        "This section is dedicated to generate the predictions of our RNN model. We first consider ten batches and obtain the predictions for them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4y9E6NK3bsY9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#output = rnnModel.predict(testData_rnn,steps=1000)\n",
        "#print(output.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EgZjsXrGhre",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_preds_targets(tf_dataset,model,nbatches = 10):\n",
        "  predictions = []\n",
        "  targets = []\n",
        "  \n",
        "\n",
        "  try:\n",
        "    iterator = tf_dataset.make_initializable_iterator()\n",
        "    next_element = iterator.get_next()\n",
        "\n",
        "    for i in range(nbatches):\n",
        "      with tf.Session() as sess:\n",
        "        sess.run(iterator.initializer)\n",
        "        inp, targ = sess.run(next_element)\n",
        "        targets.append(targ)\n",
        "        print(f\"Getting batch {i}\")\n",
        "      output = model.predict(inp)\n",
        "      predictions.append(output)\n",
        "\n",
        "  except:\n",
        "    print('something wrong!')\n",
        "    pass\n",
        "  \n",
        "  return predictions, targets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIeGeN6SltXM",
        "colab_type": "code",
        "outputId": "1d66cf1a-b9ee-4787-8068-9cf903220c10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1717
        }
      },
      "source": [
        "nbatches = 100\n",
        "predictions, targets = get_preds_targets(testData_rnn, rnnModel,nbatches)\n",
        "targets1D = np.reshape(targets,(nbatches*batchSize_rnn*seql_rnn * ninputs))\n",
        "predictions1D = np.reshape(predictions,(nbatches*batchSize_rnn*seql_rnn * ninputs))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Getting batch 0\n",
            "Getting batch 1\n",
            "Getting batch 2\n",
            "Getting batch 3\n",
            "Getting batch 4\n",
            "Getting batch 5\n",
            "Getting batch 6\n",
            "Getting batch 7\n",
            "Getting batch 8\n",
            "Getting batch 9\n",
            "Getting batch 10\n",
            "Getting batch 11\n",
            "Getting batch 12\n",
            "Getting batch 13\n",
            "Getting batch 14\n",
            "Getting batch 15\n",
            "Getting batch 16\n",
            "Getting batch 17\n",
            "Getting batch 18\n",
            "Getting batch 19\n",
            "Getting batch 20\n",
            "Getting batch 21\n",
            "Getting batch 22\n",
            "Getting batch 23\n",
            "Getting batch 24\n",
            "Getting batch 25\n",
            "Getting batch 26\n",
            "Getting batch 27\n",
            "Getting batch 28\n",
            "Getting batch 29\n",
            "Getting batch 30\n",
            "Getting batch 31\n",
            "Getting batch 32\n",
            "Getting batch 33\n",
            "Getting batch 34\n",
            "Getting batch 35\n",
            "Getting batch 36\n",
            "Getting batch 37\n",
            "Getting batch 38\n",
            "Getting batch 39\n",
            "Getting batch 40\n",
            "Getting batch 41\n",
            "Getting batch 42\n",
            "Getting batch 43\n",
            "Getting batch 44\n",
            "Getting batch 45\n",
            "Getting batch 46\n",
            "Getting batch 47\n",
            "Getting batch 48\n",
            "Getting batch 49\n",
            "Getting batch 50\n",
            "Getting batch 51\n",
            "Getting batch 52\n",
            "Getting batch 53\n",
            "Getting batch 54\n",
            "Getting batch 55\n",
            "Getting batch 56\n",
            "Getting batch 57\n",
            "Getting batch 58\n",
            "Getting batch 59\n",
            "Getting batch 60\n",
            "Getting batch 61\n",
            "Getting batch 62\n",
            "Getting batch 63\n",
            "Getting batch 64\n",
            "Getting batch 65\n",
            "Getting batch 66\n",
            "Getting batch 67\n",
            "Getting batch 68\n",
            "Getting batch 69\n",
            "Getting batch 70\n",
            "Getting batch 71\n",
            "Getting batch 72\n",
            "Getting batch 73\n",
            "Getting batch 74\n",
            "Getting batch 75\n",
            "Getting batch 76\n",
            "Getting batch 77\n",
            "Getting batch 78\n",
            "Getting batch 79\n",
            "Getting batch 80\n",
            "Getting batch 81\n",
            "Getting batch 82\n",
            "Getting batch 83\n",
            "Getting batch 84\n",
            "Getting batch 85\n",
            "Getting batch 86\n",
            "Getting batch 87\n",
            "Getting batch 88\n",
            "Getting batch 89\n",
            "Getting batch 90\n",
            "Getting batch 91\n",
            "Getting batch 92\n",
            "Getting batch 93\n",
            "Getting batch 94\n",
            "Getting batch 95\n",
            "Getting batch 96\n",
            "Getting batch 97\n",
            "Getting batch 98\n",
            "Getting batch 99\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Azevr0csK32",
        "colab_type": "text"
      },
      "source": [
        "## Postprocessing\n",
        "\n",
        "The predictions of the RNN network are processed to eliminate false peaks (oscillations below a certain threshold). We then use the function find_local_peaks to obtain the peak positions. However, since this function gives false peaks in regions where the signal is flat, we filter its result with the same threshold as before."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9-FURnHt27t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_peaks(predictions1D,targets1D):\n",
        "  # First use a threshold to eliminate some smaller peaks\n",
        "  thresh = 0.5\n",
        "  peaks = np.where(predictions1D>thresh, predictions1D, 0)\n",
        "\n",
        "  # Find local peaks in filtered predictions\n",
        "  peak_locs = find_local_peaks(peaks,8)\n",
        "\n",
        "  # Filter peak locations with condition that value of signal there must be \n",
        "  peak_locs_above_th = [p for p in peak_locs if peaks[p] > thresh]\n",
        "\n",
        "  peaks_targets1D = np.where(targets1D>thresh, targets1D, 0)\n",
        "  # Find local peaks in filtered predictions\n",
        "  targets_peak_locs = find_local_peaks(peaks_targets1D,8)\n",
        "  targets_peak_locs_above_th = [p for p in targets_peak_locs if peaks_targets1D[p] > thresh]\n",
        "\n",
        "  targets_peak_locs_above_th = np.array(targets_peak_locs_above_th)\n",
        "  peak_locs_above_th = np.array(peak_locs_above_th)\n",
        "  \n",
        "  return peak_locs_above_th, targets_peak_locs_above_th, peaks  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XtHzwNgoNc-",
        "colab_type": "text"
      },
      "source": [
        "Finding peak indexes for plotting purposes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAckmAeLhvDc",
        "colab_type": "code",
        "outputId": "b65fb313-e188-4e39-8ef0-f059f0becd17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "peak_locs_above_th, targets_peak_locs_above_th, peaks = get_peaks(predictions1D,targets1D)\n",
        "peak_locs_above_th"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([    729,    1105,    1508, ..., 4318613, 4318972, 4319691])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jupyk4GwQWm",
        "colab_type": "code",
        "outputId": "0c1f9c52-3cb9-4dbe-b10c-691ae8e58acd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        }
      },
      "source": [
        "t = range(nbatches*batchSize_rnn*seql_rnn*ninputs)\n",
        "plt.plot(t[500:2000],predictions1D[500:2000]-2,'b',t[500:2000],peaks[500:2000],'g')"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7ff3fa41c5c0>,\n",
              " <matplotlib.lines.Line2D at 0x7ff3fa55c1d0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SMVp1dPoYHN",
        "colab_type": "text"
      },
      "source": [
        "## Compare predicted peaks with annotations\n",
        "\n",
        "We now compare our predicted peaks (after postprocessing) with the labelled peaks to determine the number of peaks correctly classified by our network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i65ldSjWM4-K",
        "colab_type": "code",
        "outputId": "b6822d17-60b8-4757-9178-c03785bb8501",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "comparitor = compare_annotations(targets_peak_locs_above_th, peak_locs_above_th, 5, signal=None)\n",
        "comparitor.print_summary()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11934 reference annotations, 7743 test annotations\n",
            "\n",
            "True Positives (matched samples): 7731\n",
            "False Positives (unmatched test samples: 12\n",
            "False Negatives (unmatched reference samples): 4203\n",
            "\n",
            "Specificity: 0.6478 (7731/11934)\n",
            "Positive Predictivity: 0.9985 (7731/7743)\n",
            "False Positive Rate: 0.0015 (12/7743)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0hloy5W7Dxe",
        "colab_type": "text"
      },
      "source": [
        "# Feedforward network\n",
        "\n",
        "The architecture of the Feedforward network is designed below, similarly to what was done for the RNN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uvHOwSd7HI3",
        "colab_type": "code",
        "outputId": "11d46206-85ce-4715-9ffc-b30cac48bbc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "source": [
        "ffwdModel = tf.keras.Sequential()\n",
        "ffwdModel.add(layers.Dense(512, activation='relu',input_shape=(2*seqL*ninputs,)))\n",
        "ffwdModel.add(layers.Dense(256, activation='relu'))\n",
        "ffwdModel.add(layers.Dense(256, activation='relu'))\n",
        "ffwdModel.add(layers.Dense(64, activation='relu'))\n",
        "ffwdModel.add(layers.Dense(64, activation='relu'))\n",
        "ffwdModel.add(layers.Dense(seqL*ninputs))\n",
        "\n",
        "ffwdModel.compile(optimizer=tf.train.RMSPropOptimizer(0.001), loss='MSE',metrics=['mae'])\n",
        "ffwdModel.fit(trainData,  epochs=15, steps_per_epoch=2000, validation_data=valData, validation_steps=100)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "2000/2000 [==============================] - 8s 4ms/step - loss: 0.0156 - mean_absolute_error: 0.0333 - val_loss: 0.0156 - val_mean_absolute_error: 0.0307\n",
            "Epoch 2/15\n",
            "2000/2000 [==============================] - 7s 4ms/step - loss: 0.0154 - mean_absolute_error: 0.0356 - val_loss: 0.0157 - val_mean_absolute_error: 0.0317\n",
            "Epoch 3/15\n",
            "2000/2000 [==============================] - 7s 4ms/step - loss: 0.0152 - mean_absolute_error: 0.0368 - val_loss: 0.0157 - val_mean_absolute_error: 0.0317\n",
            "Epoch 4/15\n",
            "2000/2000 [==============================] - 7s 4ms/step - loss: 0.0151 - mean_absolute_error: 0.0376 - val_loss: 0.0157 - val_mean_absolute_error: 0.0322\n",
            "Epoch 5/15\n",
            "2000/2000 [==============================] - 7s 4ms/step - loss: 0.0151 - mean_absolute_error: 0.0380 - val_loss: 0.0157 - val_mean_absolute_error: 0.0311\n",
            "Epoch 6/15\n",
            "2000/2000 [==============================] - 7s 4ms/step - loss: 0.0150 - mean_absolute_error: 0.0381 - val_loss: 0.0157 - val_mean_absolute_error: 0.0346\n",
            "Epoch 7/15\n",
            "2000/2000 [==============================] - 7s 4ms/step - loss: 0.0150 - mean_absolute_error: 0.0382 - val_loss: 0.0156 - val_mean_absolute_error: 0.0310\n",
            "Epoch 8/15\n",
            "2000/2000 [==============================] - 7s 4ms/step - loss: 0.0150 - mean_absolute_error: 0.0382 - val_loss: 0.0156 - val_mean_absolute_error: 0.0343\n",
            "Epoch 9/15\n",
            "2000/2000 [==============================] - 8s 4ms/step - loss: 0.0150 - mean_absolute_error: 0.0381 - val_loss: 0.0156 - val_mean_absolute_error: 0.0329\n",
            "Epoch 10/15\n",
            "2000/2000 [==============================] - 7s 4ms/step - loss: 0.0150 - mean_absolute_error: 0.0379 - val_loss: 0.0157 - val_mean_absolute_error: 0.0318\n",
            "Epoch 11/15\n",
            "2000/2000 [==============================] - 7s 4ms/step - loss: 0.0150 - mean_absolute_error: 0.0379 - val_loss: 0.0156 - val_mean_absolute_error: 0.0356\n",
            "Epoch 12/15\n",
            "2000/2000 [==============================] - 7s 4ms/step - loss: 0.0150 - mean_absolute_error: 0.0378 - val_loss: 0.0155 - val_mean_absolute_error: 0.0357\n",
            "Epoch 13/15\n",
            "2000/2000 [==============================] - 7s 4ms/step - loss: 0.0149 - mean_absolute_error: 0.0376 - val_loss: 0.0156 - val_mean_absolute_error: 0.0352\n",
            "Epoch 14/15\n",
            "2000/2000 [==============================] - 7s 4ms/step - loss: 0.0149 - mean_absolute_error: 0.0376 - val_loss: 0.0156 - val_mean_absolute_error: 0.0352\n",
            "Epoch 15/15\n",
            "2000/2000 [==============================] - 7s 4ms/step - loss: 0.0149 - mean_absolute_error: 0.0376 - val_loss: 0.0156 - val_mean_absolute_error: 0.0362\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff3d4c35630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iydEe8ZtENZK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ffwd_weights_file_path = weights_path + 'FFWD_weights.h5'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsLEr85nSfUh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Saving the network weights\n",
        "ffwdModel.save_weights(ffwd_weights_file_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZoXNrZlS94a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ffwdModel.load_weights(ffwd_weights_file_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crBNa3GNTk1s",
        "colab_type": "text"
      },
      "source": [
        "## Predict - FFWD\n",
        "\n",
        "This process is analog to what was done for the RNN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ef31yOx1mPe4",
        "colab_type": "code",
        "outputId": "92808d3d-184d-4256-d124-e4ace9d0dc79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1717
        }
      },
      "source": [
        "ffwd_predictions, ffwd_targets = get_preds_targets(testData, ffwdModel,nbatches)\n",
        "ffwd_targets1D = np.reshape(ffwd_targets,(nbatches*batchSize*seqL * ninputs))\n",
        "ffwd_predictions1D = np.reshape(ffwd_predictions,(nbatches*batchSize*seqL * ninputs))"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Getting batch 0\n",
            "Getting batch 1\n",
            "Getting batch 2\n",
            "Getting batch 3\n",
            "Getting batch 4\n",
            "Getting batch 5\n",
            "Getting batch 6\n",
            "Getting batch 7\n",
            "Getting batch 8\n",
            "Getting batch 9\n",
            "Getting batch 10\n",
            "Getting batch 11\n",
            "Getting batch 12\n",
            "Getting batch 13\n",
            "Getting batch 14\n",
            "Getting batch 15\n",
            "Getting batch 16\n",
            "Getting batch 17\n",
            "Getting batch 18\n",
            "Getting batch 19\n",
            "Getting batch 20\n",
            "Getting batch 21\n",
            "Getting batch 22\n",
            "Getting batch 23\n",
            "Getting batch 24\n",
            "Getting batch 25\n",
            "Getting batch 26\n",
            "Getting batch 27\n",
            "Getting batch 28\n",
            "Getting batch 29\n",
            "Getting batch 30\n",
            "Getting batch 31\n",
            "Getting batch 32\n",
            "Getting batch 33\n",
            "Getting batch 34\n",
            "Getting batch 35\n",
            "Getting batch 36\n",
            "Getting batch 37\n",
            "Getting batch 38\n",
            "Getting batch 39\n",
            "Getting batch 40\n",
            "Getting batch 41\n",
            "Getting batch 42\n",
            "Getting batch 43\n",
            "Getting batch 44\n",
            "Getting batch 45\n",
            "Getting batch 46\n",
            "Getting batch 47\n",
            "Getting batch 48\n",
            "Getting batch 49\n",
            "Getting batch 50\n",
            "Getting batch 51\n",
            "Getting batch 52\n",
            "Getting batch 53\n",
            "Getting batch 54\n",
            "Getting batch 55\n",
            "Getting batch 56\n",
            "Getting batch 57\n",
            "Getting batch 58\n",
            "Getting batch 59\n",
            "Getting batch 60\n",
            "Getting batch 61\n",
            "Getting batch 62\n",
            "Getting batch 63\n",
            "Getting batch 64\n",
            "Getting batch 65\n",
            "Getting batch 66\n",
            "Getting batch 67\n",
            "Getting batch 68\n",
            "Getting batch 69\n",
            "Getting batch 70\n",
            "Getting batch 71\n",
            "Getting batch 72\n",
            "Getting batch 73\n",
            "Getting batch 74\n",
            "Getting batch 75\n",
            "Getting batch 76\n",
            "Getting batch 77\n",
            "Getting batch 78\n",
            "Getting batch 79\n",
            "Getting batch 80\n",
            "Getting batch 81\n",
            "Getting batch 82\n",
            "Getting batch 83\n",
            "Getting batch 84\n",
            "Getting batch 85\n",
            "Getting batch 86\n",
            "Getting batch 87\n",
            "Getting batch 88\n",
            "Getting batch 89\n",
            "Getting batch 90\n",
            "Getting batch 91\n",
            "Getting batch 92\n",
            "Getting batch 93\n",
            "Getting batch 94\n",
            "Getting batch 95\n",
            "Getting batch 96\n",
            "Getting batch 97\n",
            "Getting batch 98\n",
            "Getting batch 99\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtdPqUMoUrLu",
        "colab_type": "text"
      },
      "source": [
        "## Posprocessing\n",
        "\n",
        "Postprocessing of the predicted peaks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wo56cKuCk9Ys",
        "colab_type": "code",
        "outputId": "cc93a19f-45c9-4bef-e657-ca09e4de8ac9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "source": [
        "ffwd_peak_locs_above_th, ffwd_targets_peak_locs_above_th, ffwd_peaks = get_peaks(ffwd_predictions1D,ffwd_targets1D)\n",
        "ffwd_peak_locs_above_th"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([    879,    4145,   13276,   15266,   19158,   33312,   38516,\n",
              "         42312,   54567,   62394,   67316,   69594,   73270,   78076,\n",
              "         82258,   84058,  100158,  112759,  116355,  120058,  128516,\n",
              "        137994,  148479,  151767,  154025,  159412,  161358,  167967,\n",
              "        179066,  180567,  186425,  195740,  198716,  205894,  226025,\n",
              "        229479,  234716,  238794,  240558,  247229,  258094,  258658,\n",
              "        262025,  263429,  276412,  278458,  281494,  287112,  301167,\n",
              "        303312,  303594,  315676,  326516,  328316,  328868,  335367,\n",
              "        339554,  341225,  347903,  350394,  353679,  362994,  371345,\n",
              "        378676,  394829,  395394,  403916,  407516,  408068,  422458,\n",
              "        423567,  425825,  432545,  445858,  452994,  454794,  456740,\n",
              "        461825,  467540,  470516,  471068,  473903,  479994,  483670,\n",
              "        484916,  488679,  511876,  546238,  571103,  573279,  573559,\n",
              "        574780,  580889,  587345,  609412,  629489,  631194,  635980,\n",
              "        641679,  645116,  651140,  657912,  667012,  671903,  682916,\n",
              "        688858,  690279,  708425,  710225,  717412,  719540,  722345,\n",
              "        726425,  731994,  740994,  747567,  757258,  762658,  766025,\n",
              "        776303,  785679,  796276,  805512,  807279,  813070,  814103,\n",
              "        816594,  823145,  841794,  844767,  848345,  850438,  852425,\n",
              "        853767,  855866,  880767,  883194,  895316,  897670,  904316,\n",
              "        911679,  911957,  913466,  915670,  917412,  927629,  938825,\n",
              "        944458,  954694,  964258,  967625,  982194, 1005425, 1006829,\n",
              "       1010812, 1028494, 1030794, 1032689, 1045025, 1046712, 1046994,\n",
              "       1050559, 1079489, 1081159, 1082994, 1084754, 1099194, 1100429,\n",
              "       1104594, 1105829, 1106394, 1113279, 1113555, 1115394, 1120794,\n",
              "       1129794, 1131412, 1136679, 1140558, 1143838, 1151358, 1158558,\n",
              "       1168745, 1179567, 1183167, 1183438, 1187225, 1192940, 1210479,\n",
              "       1214489, 1228858, 1239594, 1252340, 1258745, 1275740, 1286458,\n",
              "       1288212, 1292903, 1302425, 1307825, 1327794, 1332503, 1342012,\n",
              "       1345167, 1347094, 1351194, 1352679, 1354316, 1354868, 1363794,\n",
              "       1375876, 1381316, 1381868, 1403079, 1408294, 1414159, 1415638,\n",
              "       1419594, 1426103])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2LC5f23WQY3",
        "colab_type": "code",
        "outputId": "66b6b298-ddde-49e8-9931-e3cb22fe7fd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        }
      },
      "source": [
        "ffwd_t = range(nbatches*batchSize*seqL*ninputs)\n",
        "plt.plot(ffwd_t[23000:60000],ffwd_predictions1D[23000:60000]-2,'b',ffwd_t[23000:60000],ffwd_peaks[23000:60000],'g')"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7ff3d485aa58>,\n",
              " <matplotlib.lines.Line2D at 0x7ff3d485aba8>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niGTU/wdI/WZYgAX0YgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gio1ysGZpNWA",
        "colab_type": "text"
      },
      "source": [
        "## Compare predicted peaks with annotations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7LO1AsVVrWg",
        "colab_type": "code",
        "outputId": "ce683b90-09b7-4c2d-8a3f-d93d4a41219a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "ffwd_comparitor = compare_annotations(ffwd_targets_peak_locs_above_th, ffwd_peak_locs_above_th, 5, signal=None)\n",
        "ffwd_comparitor.print_summary()"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5346 reference annotations, 219 test annotations\n",
            "\n",
            "True Positives (matched samples): 190\n",
            "False Positives (unmatched test samples: 29\n",
            "False Negatives (unmatched reference samples): 5156\n",
            "\n",
            "Specificity: 0.0355 (190/5346)\n",
            "Positive Predictivity: 0.8676 (190/219)\n",
            "False Positive Rate: 0.1324 (29/219)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}